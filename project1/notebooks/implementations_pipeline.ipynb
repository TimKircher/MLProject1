{
 "cells": [
  {

   "cell_type": "markdown",
   "id": "c4ff6c2b-b6ac-4914-8e1f-1bd1182c258e",
   "metadata": {},
   "source": [
    "# Implementations pipeline\n",
    "##### In this notebook we test our implemented ML methods (regressions) and we test their accuracy\n",
    "We begin by importing the libraries that we are going to need for this procedure and initialising the constants that are going to be used for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0673e06-1a3f-4592-9e3f-ef2c086c60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SCRIPTS_FILEPATH = \"./../scripts/\"\n",
    "DATA_FILEPATH = \"../data/train.csv\"\n",
    "\n",
    "sys.path.append(SCRIPTS_FILEPATH)\n",
    "from implementations import *\n",
    "from compute import *\n",
    "from data_cleaner import Data_Cleaner\n",
    "from proj1_helpers import predict_labels\n",
    "\n",
    "lambda_= 1e-6\n",
    "max_iters = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c919acd-6dc9-452b-87c6-f15106c8d387",
   "metadata": {},
   "source": [
    "We will train our models using 3 different versions of the same dataset. We do this to able to compare the impact of feature engineering in our implementations.\n",
    "1. Raw data : The data is loaded, the missing variables and the outliers are treated. Then the data is normalized\n",
    "2. Polynomial data : The data is loaded, the missing variables and the outliers are treated. Polynomial feature expansion is applied. The data is normalized.\n",
    "3. Interactions data : The data is loaded, the missing variables and the outliers are treated. Feature interaction is applied. The data is normalized.\n",
    "\n",
    "In all cases the dataset is split in 2 so we can estimate the performance of the model on the validation set :\n",
    "- Training dataset (80%)\n",
    "- Test validation dataset (20%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00680f94-6196-4996-bb68-30c55eb0cfe7",
   "metadata": {},
   "source": [
    "## Raw data\n"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "58244dbd-b6a9-4961-bb85-1ce6cd4a5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "data.treat_outliers(1.5,92.5)\n",
    "data.normalize()\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "initial_w = np.zeros(tX_train.shape[1])"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "142afb7c-781d-461d-aa7a-2d19095dcccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115dc80-2cd3-4942-9895-d1d6fa6deaf0",
   "metadata": {},
   "source": [
    "We Create our models using different regressions but every time using the same training set that we have mentioned before. Then we predict the variables of our test set and test the accuracy of our predictions : "

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "b4631fe8-29bf-4da3-bdc2-39e31c430c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares_GD(y_train, tX_train, np.copy(initial_w), max_iters, gamma =1e-1)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "870e0490-13f5-4deb-afc0-05b71e2d64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares_SGD(y_train, tX_train, np.copy(initial_w), max_iters, gamma = 1e-3)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "2c7aec03-d0ac-4c72-8ece-e33a69ab625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, tX_train)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "c5edd8ee-94d5-404e-8ac1-6b0aa1fe493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = ridge_regression(y_train, tX_train, lambda_)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926de887-3ab1-4d28-bca3-f512607f5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = logistic_regression(y_train, tX_train, np.copy(initial_w), 1000, gamma = 1e-6)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb479f-3d69-4587-a68f-5c4cfb3239e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = reg_logistic_regression(y_train, tX_train,lambda_ , np.copy(initial_w), max_iters, gamma=1e-5)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415a684-0294-46f4-a049-d990175d79eb",
   "metadata": {},
   "source": [
    "## Polynomial data"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "9eb7dc7f-c370-4454-83e0-5290dbdc5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "data.treat_outliers(1.5,92.5)\n",
    "data.build_polynomial(2)\n",
    "data.normalize()\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "initial_w = np.zeros(tX_train.shape[1])"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "d4f9f1e5-7863-4b7b-9dd0-ca167100f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares_GD(y_train, tX_train, np.copy(initial_w), max_iters, gamma =1e-1)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "855c92ea-10ce-46e0-95a4-25114ee634a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares_SGD(y_train, tX_train, np.copy(initial_w), max_iters, gamma = 1e-3)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "f0d240c2-060e-4208-8dd7-bfe1126b85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, tX_train)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "0d66e606-a1dd-4e57-9286-b5a7f86788b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = ridge_regression(y_train, tX_train, lambda_)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "46292ec2-fbda-47e6-96cb-b01efbeb29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = logistic_regression(y_train, tX_train, np.copy(initial_w), 1000, gamma = 1e-6)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "f5761c2c-b885-46cf-8dac-4056222e96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = reg_logistic_regression(y_train, tX_train,lambda_ , np.copy(initial_w), max_iters, gamma=1e-5)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fef76f-47a2-4796-a80c-9412b8e308e0",
   "metadata": {},
   "source": [
    "## Interactions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa514f-5775-4847-bf28-cd101ad715f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "data.treat_outliers(1.5,92.5)\n",
    "data.build_interactions()\n",
    "data.normalize()\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "initial_w = np.zeros(tX_train.shape[1])"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "cdd559b5-c93d-496e-bd55-71d5b471f154",

   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, tX_train)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",

    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "ad24fd69-6903-4140-a7cd-5b542b25c378",

   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = ridge_regression(y_train, tX_train, lambda_)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",

    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "7c6f610b-b59a-4906-b76a-f8f3e0c2615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = logistic_regression(y_train, tX_train, np.copy(initial_w), 1000, gamma = 1e-6)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "a7f46859-b818-47a5-84db-e4823509f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = reg_logistic_regression(y_train, tX_train,lambda_ , np.copy(initial_w), max_iters, gamma=1e-5)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"

   ]
  }
 ],
 "metadata": {
  "kernelspec": {

   "display_name": "Python 3",
   "language": "python",
   "name": "python3"

  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",

   "version": "3.8.8"

  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
