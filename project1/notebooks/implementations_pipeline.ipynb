{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af43e01-dcc4-4309-a23b-e503d014a540",
   "metadata": {},
   "source": [
    "# Implementations pipeline\n",
    "##### In this notebook we test our implemented ML methods (regressions) and we test their accuracy\n",
    "We begin by importing the libraries that we are going to need for this procedure and initialising the constants that are going to be used for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ca802e-ac9f-4cbb-8ec1-ab406840335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SCRIPTS_FILEPATH = \"../scripts/\"\n",
    "DATA_FILEPATH = \"../data/train.csv\"\n",
    "\n",
    "sys.path.append(SCRIPTS_FILEPATH)\n",
    "from implementations import *\n",
    "from compute import *\n",
    "from data_cleaner import Data_Cleaner\n",
    "from proj1_helpers import predict_labels\n",
    "from linear_model_base import RidgeRegression\n",
    "from linear_model_base import LogisiticRegression\n",
    "\n",
    "\n",
    "max_iters = 1000\n",
    "search_space = np.logspace(-15, -5, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999a847-92d9-444c-a752-229cc840351b",
   "metadata": {},
   "source": [
    "We will train our models using 3 different versions of the same dataset. We do this to able to compare the impact of feature engineering in our implementations.\n",
    "1. Raw data : The data is loaded, the missing variables and the outliers are treated. Then the data is normalized\n",
    "2. Polynomial data : The data is loaded, the missing variables and the outliers are treated. Polynomial feature expansion is applied. The data is normalized.\n",
    "3. Interactions data : The data is loaded, the missing variables and the outliers are treated. Feature interaction is applied. The data is normalized.\n",
    "4. Polynomial & Interactions data : The data is loaded, the missing variables and the outliers are treated. Polynomial feature expansion and feature interaction is applied. The data is normalized.\n",
    "5. Final model: The data is loaded, the missing variables and the outliers are treated. Feature interaction is applied. Polynomial feature expansion, feature interaction and logarithmic scale is applied\n",
    "\n",
    "In all cases the dataset is split in 2 so we can estimate the performance of the model on the validation set :\n",
    "- Training dataset (80%)\n",
    "- Test validation dataset (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9e4d1-8df3-4017-9581-cce2702df433",
   "metadata": {},
   "source": [
    "## 1. Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f76fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "\n",
    "#split\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "\n",
    "#generate for minmax scale\n",
    "data_train = Data_Cleaner()\n",
    "data_train.tX = tX_train\n",
    "data_train.y = y_train\n",
    "\n",
    "#generate for minmax scale\n",
    "data_test = Data_Cleaner()\n",
    "data_test.tX = tX_test\n",
    "data_test.y = y_test\n",
    "\n",
    "#scale\n",
    "minimum, maximum = data_train.getMinMax()\n",
    "data_train.standardize()\n",
    "data_test.tX = (data_test.tX-minimum)/(maximum-minimum)\n",
    "\n",
    "y_train = data_train.y\n",
    "tX_train = data_train.tX\n",
    "\n",
    "y_test = data_test.y\n",
    "tX_test = data_test.tX\n",
    "\n",
    "initial_w = np.zeros(tX_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b2496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration :0, loss= 0.5000\n",
      "Current iteration :250, loss= 0.3889\n",
      "Current iteration :500, loss= 0.3827\n",
      "Current iteration :750, loss= 0.3787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70546"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, loss = least_squares_GD(y_train, tX_train, np.copy(initial_w), max_iters, gamma =1e-1)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66144853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration :0, loss= 0.5000\n",
      "Current iteration :250, loss= 0.3477\n",
      "Current iteration :500, loss= 0.2527\n",
      "Current iteration :750, loss= 0.2744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65674"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, loss = least_squares_SGD(y_train, tX_train, np.copy(initial_w), max_iters, gamma = 1e-3)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577c8032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74786"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, loss = least_squares(y_train, tX_train)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c770afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7478"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_te = []\n",
    "rmse_tr = []\n",
    "\n",
    "data_train = Data_Cleaner()\n",
    "data_train.tX = tX_train\n",
    "data_train.y = y_train\n",
    "\n",
    "Model = RidgeRegression(data_train)\n",
    "for lambda_ in search_space:\n",
    "        \n",
    "    tr, te = Model.cross_validation(5, lambda_=lambda_)\n",
    "    rmse_te.append(te)\n",
    "    rmse_tr.append(tr) \n",
    "\n",
    "best_lambda = search_space[np.where(rmse_te==np.min(rmse_te))]\n",
    "Model = RidgeRegression(data_train)\n",
    "weights = Model._run(lambda_ = best_lambda)\n",
    "\n",
    "y_pred =  predict_labels(weights,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de77eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6826958e-14])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ac882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration :0, loss= 138629.4361\n",
      "Current iteration :250, loss= -503868.9187\n",
      "Current iteration :500, loss= -503868.9187\n",
      "Current iteration :750, loss= -503868.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65674"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, loss = logistic_regression(y_train, tX_train, np.copy(initial_w), 1000, gamma = 1e-3)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9724cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration :0, loss= 138629.4361\n",
      "Current iteration :250, loss= -495958.0256\n",
      "Current iteration :500, loss= -472435.8213\n",
      "Current iteration :750, loss= -433302.1641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65674"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 1e-5\n",
    "w, loss = reg_logistic_regression(y_train, tX_train,lambda_, np.copy(initial_w), max_iters, gamma=1e-3)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a47a6-12b2-4584-ae71-57dedbce1e3b",
   "metadata": {},
   "source": [
    "## 2. Polynomial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1179102a-b749-4eba-9f28-86a716afeb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77456"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "data.build_polynomial(2)\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "\n",
    "#generate for minmax scale\n",
    "data_train = Data_Cleaner()\n",
    "data_train.tX = tX_train\n",
    "data_train.y = y_train\n",
    "\n",
    "#generate for minmax scale\n",
    "data_test = Data_Cleaner()\n",
    "data_test.tX = tX_test\n",
    "data_test.y = y_test\n",
    "\n",
    "#scale\n",
    "minimum, maximum = data_train.getMinMax()\n",
    "data_train.standardize()\n",
    "data_test.tX = (data_test.tX-minimum)/(maximum-minimum)\n",
    "\n",
    "rmse_te = []\n",
    "rmse_tr = []\n",
    "\n",
    "Model = RidgeRegression(data_train)\n",
    "for lambda_ in search_space:\n",
    "        \n",
    "    tr, te = Model.cross_validation(5, lambda_=lambda_)\n",
    "    rmse_te.append(te)\n",
    "    rmse_tr.append(tr) \n",
    "\n",
    "best_lambda = search_space[np.where(rmse_te==np.min(rmse_te))]\n",
    "Model = RidgeRegression(data_train)\n",
    "weights = Model._run(lambda_ = best_lambda)\n",
    "\n",
    "y_pred =  predict_labels(weights,data_test.tX)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bdfb0-00f8-433d-a248-a176feead10c",
   "metadata": {},
   "source": [
    "## 3. Interactions data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb15489d-d0f1-40b2-8b1f-13b1199f781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "data.build_interactions()\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "\n",
    "#generate for minmax scale\n",
    "data_train = Data_Cleaner()\n",
    "data_train.tX = tX_train\n",
    "data_train.y = y_train\n",
    "\n",
    "#generate for minmax scale\n",
    "data_test = Data_Cleaner()\n",
    "data_test.tX = tX_test\n",
    "data_test.y = y_test\n",
    "\n",
    "#scale\n",
    "minimum, maximum = data_train.getMinMax()\n",
    "data_train.standardize()\n",
    "data_test.tX = (data_test.tX-minimum)/(maximum-minimum)\n",
    "\n",
    "rmse_te = []\n",
    "rmse_tr = []\n",
    "\n",
    "Model = RidgeRegression(data_train)\n",
    "for lambda_ in search_space:\n",
    "        \n",
    "    tr, te = Model.cross_validation(5, lambda_=lambda_)\n",
    "    rmse_te.append(te)\n",
    "    rmse_tr.append(tr) \n",
    "\n",
    "best_lambda = search_space[np.where(rmse_te==np.min(rmse_te))]\n",
    "Model = RidgeRegression(data_train)\n",
    "weights = Model._run(lambda_ = best_lambda)\n",
    "\n",
    "y_pred =  predict_labels(weights,data_test.tX)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b0b34-d99a-4241-81e9-5a4953085a4b",
   "metadata": {},
   "source": [
    "## 4. Polynomial & Interactions data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b582d5-b67e-48a3-a807-5c8f83089ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81518"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#interaction terms and polynomial features\n",
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "data.build_polynomial(2)\n",
    "data.build_interactions()\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "\n",
    "#generate for minmax scale\n",
    "data_train = Data_Cleaner()\n",
    "data_train.tX = tX_train\n",
    "data_train.y = y_train\n",
    "\n",
    "#generate for minmax scale\n",
    "data_test = Data_Cleaner()\n",
    "data_test.tX = tX_test\n",
    "data_test.y = y_test\n",
    "\n",
    "#scale\n",
    "minimum, maximum = data_train.getMinMax()\n",
    "data_train.standardize()\n",
    "data_test.tX = (data_test.tX-minimum)/(maximum-minimum)\n",
    "\n",
    "rmse_te = []\n",
    "rmse_tr = []\n",
    "\n",
    "Model = RidgeRegression(data_train)\n",
    "for lambda_ in search_space:\n",
    "        \n",
    "    tr, te = Model.cross_validation(5, lambda_=lambda_)\n",
    "    rmse_te.append(te)\n",
    "    rmse_tr.append(tr) \n",
    "\n",
    "best_lambda = search_space[np.where(rmse_te==np.min(rmse_te))]\n",
    "Model = RidgeRegression(data_train)\n",
    "weights = Model._run(lambda_ = best_lambda)\n",
    "\n",
    "y_pred =  predict_labels(weights,data_test.tX)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b004c2-9d84-4a64-a71e-661f52d61273",
   "metadata": {},
   "source": [
    "## 5. Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530115bf-002b-47c5-a41c-ff199cf17a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83564"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_one()\n",
    "#find columns with multiscale input (max greater than 100)\n",
    "log_columns = np.max(data.tX, axis=0)>100\n",
    "#log(x+1) of columns with multiscale data, to ensure no x <= 0\n",
    "data.tX[:,log_columns] = np.log(data.tX[:,log_columns]+1)\n",
    "data.build_polynomial(2)\n",
    "data.build_interactions()\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "\n",
    "#generate for minmax scale\n",
    "data_train = Data_Cleaner()\n",
    "data_train.tX = tX_train\n",
    "data_train.y = y_train\n",
    "\n",
    "#generate for minmax scale\n",
    "data_test = Data_Cleaner()\n",
    "data_test.tX = tX_test\n",
    "data_test.y = y_test\n",
    "\n",
    "#remove outliers\n",
    "data_test.treat_outliers(1.5,92.5)\n",
    "data_train.treat_outliers(1.5,92.5)\n",
    "\n",
    "#scale\n",
    "minimum, maximum = data_train.getMinMax()\n",
    "data_train.standardize()\n",
    "data_test.tX = (data_test.tX-minimum)/(maximum-minimum)\n",
    "\n",
    "rmse_te = []\n",
    "rmse_tr = []\n",
    "\n",
    "Model = RidgeRegression(data_train)\n",
    "for lambda_ in search_space:\n",
    "        \n",
    "    tr, te = Model.cross_validation(5, lambda_=lambda_)\n",
    "    rmse_te.append(te)\n",
    "    rmse_tr.append(tr) \n",
    "\n",
    "best_lambda = search_space[np.where(rmse_te==np.min(rmse_te))]\n",
    "Model = RidgeRegression(data_train)\n",
    "weights = Model._run(lambda_ = best_lambda)\n",
    "\n",
    "y_pred =  predict_labels(weights,data_test.tX)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
