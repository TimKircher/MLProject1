{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ff6c2b-b6ac-4914-8e1f-1bd1182c258e",
   "metadata": {},
   "source": [
    "# Implementations pipeline\n",
    "##### In this notebook we test our implemented ML methods (regressions) and we test their accuracy\n",
    "We begin by importing the libraries that we are going to need for this procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0673e06-1a3f-4592-9e3f-ef2c086c60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SCRIPTS_FILEPATH = \"./../scripts/\"\n",
    "DATA_FILEPATH = \"../data/train.csv\"\n",
    "\n",
    "sys.path.append(SCRIPTS_FILEPATH)\n",
    "from implementations import *\n",
    "from compute import *\n",
    "from data_cleaner import Data_Cleaner\n",
    "from proj1_helpers import predict_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c919acd-6dc9-452b-87c6-f15106c8d387",
   "metadata": {},
   "source": [
    "We follow by loading our data, treating the variables that are indicated as \"may be undefined\" and we normalize our dataset. Then we proceed by splitting our dataset in 2 :\n",
    "1. Training dataset (80%)\n",
    "2. Test dataset (20%)\n",
    "\n",
    "Finally, we set the constants that we are going to use for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f34ff-e3e2-426c-8ae8-e2b9e129b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data_Cleaner(DATA_FILEPATH)\n",
    "data._fill_with_NaN()\n",
    "data.fix_mass_MMC()\n",
    "data.replace_with_zero()\n",
    "data.treat_outliers(1.5,92.5)\n",
    "data.normalize()\n",
    "\n",
    "tX_train, tX_test, y_train, y_test = data.split_data(80)\n",
    "  \n",
    "lambda_= 1e-5\n",
    "max_iters = 1000\n",
    "initial_w = np.zeros(tX_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115dc80-2cd3-4942-9895-d1d6fa6deaf0",
   "metadata": {},
   "source": [
    "We Create our models using different regressions but every time using the same training set that we have mentioned before. Then we predict the variables of our test set and test the accuracy of our predictions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5988121-bc33-4580-b16d-4eee2a94ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares_GD(y_train, tX_train, np.copy(initial_w), max_iters, gamma =1e-1)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04089c0-8533-47de-9bb9-16105d27c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares_SGD(y_train, tX_train, np.copy(initial_w), max_iters, gamma = 1e-3)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910db935-6f5e-41e3-91bd-d6b20e9aac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = least_squares(y_train, tX_train)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06eaa28-6dfc-4dcc-9029-ce173dae06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = ridge_regression(y_train, tX_train, lambda_)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf86a89-0e4c-47f1-b6b5-d2f1056199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = logistic_regression(y_train, tX_train, np.copy(initial_w), 1000, gamma = 1e-6)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eba8e8-67a4-4043-a950-a5870cf1d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = reg_logistic_regression(y_train, tX_train,lambda_ , np.copy(initial_w), max_iters, gamma=1e-5)\n",
    "y_pred =  predict_labels(w,tX_test)\n",
    "\n",
    "compute_leaderboard_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
